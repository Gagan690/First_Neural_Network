{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c109995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader , Dataset\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe62071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMI_Dataset(Dataset):\n",
    "  def __init__(self, csv_path):\n",
    "    super().__init__()\n",
    "    self.df = pd.read_csv(csv_path)\n",
    "    self.df['Gender'] = self.df['Gender'].replace({'Male': 1, 'Female': 0})\n",
    "    self.data = self.df.to_numpy() # Use self.df here\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.data.shape[0]\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    features = torch.tensor(self.data[idx, :-1]).float() # Convert to float\n",
    "    labels = torch.tensor(self.data[idx,-1]).long() # Convert to long for classification\n",
    "    return features , labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe0f464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a6dff14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: tensor([[  1., 161., 155.],\n",
      "        [  0., 163., 159.],\n",
      "        [  1., 148., 141.],\n",
      "        [  1., 173., 139.],\n",
      "        [  1., 169., 136.],\n",
      "        [  1., 188., 100.],\n",
      "        [  0., 167.,  85.],\n",
      "        [  1., 144.,  88.],\n",
      "        [  0., 164., 160.],\n",
      "        [  1., 196., 116.],\n",
      "        [  1., 141.,  86.],\n",
      "        [  1., 159., 104.],\n",
      "        [  0., 161., 154.],\n",
      "        [  0., 195., 147.],\n",
      "        [  1., 177., 117.],\n",
      "        [  1., 140.,  79.]])\n",
      "Labels: tensor([5, 5, 5, 5, 5, 3, 4, 5, 5, 4, 5, 5, 5, 4, 4, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_1808\\1442832286.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  self.df['Gender'] = self.df['Gender'].replace({'Male': 1, 'Female': 0})\n"
     ]
    }
   ],
   "source": [
    "dataset = BMI_Dataset('Dataset/bmi.csv')\n",
    "dataloader_train = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "features, labels = next(iter(dataloader_train))\n",
    "print(f\"Features: {features}\")\n",
    "print(f\"Labels: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4f92239",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.fc1 = nn.Linear(3,9)\n",
    "    self.fc2 = nn.Linear(9,12)\n",
    "    self.fc3 = nn.Linear(12,15)\n",
    "    self.fc4 = nn.Linear(15,9)\n",
    "    self.fc5 = nn.Linear(9,6) # Changed output features to 6\n",
    "    # Removed self.fc6 = nn.Linear(3,1)\n",
    "    # Removed self.softmax = nn.Softmax(dim=1)\n",
    "  def forward(self,x):\n",
    "    x = F.elu(self.fc1(x))\n",
    "    x = F.elu(self.fc2(x))\n",
    "    x = F.elu(self.fc3(x))\n",
    "    x = F.elu(self.fc4(x))\n",
    "    x = self.fc5(x) # Removed ELU activation and moved to the output layer\n",
    "    # Removed x = self.softmax(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93cc4a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f34dcd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b306e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader_train, criterion, optimizer, epochs):\n",
    "  model.train()\n",
    "  for epoch in range(epochs):\n",
    "    for features , labels in dataloader_train:\n",
    "      optimizer.zero_grad()\n",
    "      output = model(features)\n",
    "      loss = criterion(output, labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c00708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader_test, criterion):\n",
    "  model.eval()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  with torch.no_grad():\n",
    "    for features, labels in dataloader_test:\n",
    "      output = model(features)\n",
    "      #total += criterion(output, labels).item()\n",
    "      pred = output.argmax(dim=1)\n",
    "      total += labels.size(0)\n",
    "      correct += (output.argmax(dim=1) == labels).sum().item()\n",
    "  accuracy = (correct / total) * 100 # Convert to percentage\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60f139b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150, Loss: 1.1938589811325073\n",
      "Epoch 2/150, Loss: 1.6835688352584839\n",
      "Epoch 3/150, Loss: 1.3795595169067383\n",
      "Epoch 4/150, Loss: 1.6296440362930298\n",
      "Epoch 5/150, Loss: 1.4694089889526367\n",
      "Epoch 6/150, Loss: 1.0754302740097046\n",
      "Epoch 7/150, Loss: 1.0672402381896973\n",
      "Epoch 8/150, Loss: 1.462502121925354\n",
      "Epoch 9/150, Loss: 0.8524600267410278\n",
      "Epoch 10/150, Loss: 1.3686193227767944\n",
      "Epoch 11/150, Loss: 0.8586801886558533\n",
      "Epoch 12/150, Loss: 1.310300588607788\n",
      "Epoch 13/150, Loss: 0.6529605388641357\n",
      "Epoch 14/150, Loss: 0.979171872138977\n",
      "Epoch 15/150, Loss: 0.7287566661834717\n",
      "Epoch 16/150, Loss: 0.5455722808837891\n",
      "Epoch 17/150, Loss: 0.6849369406700134\n",
      "Epoch 18/150, Loss: 0.5825262665748596\n",
      "Epoch 19/150, Loss: 1.0687988996505737\n",
      "Epoch 20/150, Loss: 1.4606971740722656\n",
      "Epoch 21/150, Loss: 0.4502708613872528\n",
      "Epoch 22/150, Loss: 1.2727830410003662\n",
      "Epoch 23/150, Loss: 1.0218617916107178\n",
      "Epoch 24/150, Loss: 0.6880232095718384\n",
      "Epoch 25/150, Loss: 1.11202073097229\n",
      "Epoch 26/150, Loss: 0.958993136882782\n",
      "Epoch 27/150, Loss: 0.5824394822120667\n",
      "Epoch 28/150, Loss: 1.0086309909820557\n",
      "Epoch 29/150, Loss: 0.6267802119255066\n",
      "Epoch 30/150, Loss: 0.6378414630889893\n",
      "Epoch 31/150, Loss: 1.110748529434204\n",
      "Epoch 32/150, Loss: 0.36582720279693604\n",
      "Epoch 33/150, Loss: 0.4141896963119507\n",
      "Epoch 34/150, Loss: 0.3769010305404663\n",
      "Epoch 35/150, Loss: 0.3299553394317627\n",
      "Epoch 36/150, Loss: 1.2399839162826538\n",
      "Epoch 37/150, Loss: 0.8865948915481567\n",
      "Epoch 38/150, Loss: 0.6337775588035583\n",
      "Epoch 39/150, Loss: 0.7707547545433044\n",
      "Epoch 40/150, Loss: 0.5948082804679871\n",
      "Epoch 41/150, Loss: 0.3233203589916229\n",
      "Epoch 42/150, Loss: 0.6134680509567261\n",
      "Epoch 43/150, Loss: 0.8714910745620728\n",
      "Epoch 44/150, Loss: 0.7335139513015747\n",
      "Epoch 45/150, Loss: 0.3108196258544922\n",
      "Epoch 46/150, Loss: 1.0763853788375854\n",
      "Epoch 47/150, Loss: 0.6562583446502686\n",
      "Epoch 48/150, Loss: 0.8541631698608398\n",
      "Epoch 49/150, Loss: 0.39156368374824524\n",
      "Epoch 50/150, Loss: 0.6333120465278625\n",
      "Epoch 51/150, Loss: 0.981338620185852\n",
      "Epoch 52/150, Loss: 0.3631659746170044\n",
      "Epoch 53/150, Loss: 0.532036542892456\n",
      "Epoch 54/150, Loss: 0.5800685286521912\n",
      "Epoch 55/150, Loss: 0.36045876145362854\n",
      "Epoch 56/150, Loss: 0.6821946501731873\n",
      "Epoch 57/150, Loss: 0.26940956711769104\n",
      "Epoch 58/150, Loss: 0.2736356258392334\n",
      "Epoch 59/150, Loss: 0.21078187227249146\n",
      "Epoch 60/150, Loss: 1.181908130645752\n",
      "Epoch 61/150, Loss: 0.8146852254867554\n",
      "Epoch 62/150, Loss: 0.421649307012558\n",
      "Epoch 63/150, Loss: 0.773874044418335\n",
      "Epoch 64/150, Loss: 0.5343061685562134\n",
      "Epoch 65/150, Loss: 1.1862125396728516\n",
      "Epoch 66/150, Loss: 0.29114264249801636\n",
      "Epoch 67/150, Loss: 0.1486804038286209\n",
      "Epoch 68/150, Loss: 0.6417872309684753\n",
      "Epoch 69/150, Loss: 0.7035365104675293\n",
      "Epoch 70/150, Loss: 0.7448087930679321\n",
      "Epoch 71/150, Loss: 1.0893630981445312\n",
      "Epoch 72/150, Loss: 0.46688589453697205\n",
      "Epoch 73/150, Loss: 1.0222840309143066\n",
      "Epoch 74/150, Loss: 0.4968136250972748\n",
      "Epoch 75/150, Loss: 1.3168582916259766\n",
      "Epoch 76/150, Loss: 0.9282556176185608\n",
      "Epoch 77/150, Loss: 0.2533389627933502\n",
      "Epoch 78/150, Loss: 0.6458432078361511\n",
      "Epoch 79/150, Loss: 0.5340900421142578\n",
      "Epoch 80/150, Loss: 0.39504796266555786\n",
      "Epoch 81/150, Loss: 0.936378002166748\n",
      "Epoch 82/150, Loss: 0.1006435975432396\n",
      "Epoch 83/150, Loss: 0.455381840467453\n",
      "Epoch 84/150, Loss: 0.4889810085296631\n",
      "Epoch 85/150, Loss: 0.8400797843933105\n",
      "Epoch 86/150, Loss: 1.0204039812088013\n",
      "Epoch 87/150, Loss: 0.6905560493469238\n",
      "Epoch 88/150, Loss: 0.2135266363620758\n",
      "Epoch 89/150, Loss: 0.4199526011943817\n",
      "Epoch 90/150, Loss: 0.9303349256515503\n",
      "Epoch 91/150, Loss: 0.21024423837661743\n",
      "Epoch 92/150, Loss: 0.2908928692340851\n",
      "Epoch 93/150, Loss: 0.1588432341814041\n",
      "Epoch 94/150, Loss: 0.6203218698501587\n",
      "Epoch 95/150, Loss: 0.4908447861671448\n",
      "Epoch 96/150, Loss: 0.11879591643810272\n",
      "Epoch 97/150, Loss: 0.6362068057060242\n",
      "Epoch 98/150, Loss: 0.49861764907836914\n",
      "Epoch 99/150, Loss: 0.27551594376564026\n",
      "Epoch 100/150, Loss: 0.7042468786239624\n",
      "Epoch 101/150, Loss: 0.2926124632358551\n",
      "Epoch 102/150, Loss: 0.23306682705879211\n",
      "Epoch 103/150, Loss: 1.0470080375671387\n",
      "Epoch 104/150, Loss: 0.525833010673523\n",
      "Epoch 105/150, Loss: 0.27655965089797974\n",
      "Epoch 106/150, Loss: 0.26074540615081787\n",
      "Epoch 107/150, Loss: 0.48573166131973267\n",
      "Epoch 108/150, Loss: 0.9258519411087036\n",
      "Epoch 109/150, Loss: 0.32393068075180054\n",
      "Epoch 110/150, Loss: 0.5901299715042114\n",
      "Epoch 111/150, Loss: 0.6415765285491943\n",
      "Epoch 112/150, Loss: 0.5961456298828125\n",
      "Epoch 113/150, Loss: 0.6436380743980408\n",
      "Epoch 114/150, Loss: 0.8672630786895752\n",
      "Epoch 115/150, Loss: 1.3418723344802856\n",
      "Epoch 116/150, Loss: 0.9274113178253174\n",
      "Epoch 117/150, Loss: 0.3230421245098114\n",
      "Epoch 118/150, Loss: 1.1386717557907104\n",
      "Epoch 119/150, Loss: 0.5470036268234253\n",
      "Epoch 120/150, Loss: 0.5622137188911438\n",
      "Epoch 121/150, Loss: 0.3503139317035675\n",
      "Epoch 122/150, Loss: 0.007504597306251526\n",
      "Epoch 123/150, Loss: 0.5308247804641724\n",
      "Epoch 124/150, Loss: 1.1692126989364624\n",
      "Epoch 125/150, Loss: 0.42452579736709595\n",
      "Epoch 126/150, Loss: 1.4961990118026733\n",
      "Epoch 127/150, Loss: 1.3749361038208008\n",
      "Epoch 128/150, Loss: 0.33866485953330994\n",
      "Epoch 129/150, Loss: 0.3276072144508362\n",
      "Epoch 130/150, Loss: 0.5608389973640442\n",
      "Epoch 131/150, Loss: 0.44707953929901123\n",
      "Epoch 132/150, Loss: 0.7060427665710449\n",
      "Epoch 133/150, Loss: 0.704085648059845\n",
      "Epoch 134/150, Loss: 1.4394789934158325\n",
      "Epoch 135/150, Loss: 0.28142598271369934\n",
      "Epoch 136/150, Loss: 1.1744804382324219\n",
      "Epoch 137/150, Loss: 0.46585267782211304\n",
      "Epoch 138/150, Loss: 0.4110116958618164\n",
      "Epoch 139/150, Loss: 0.32618749141693115\n",
      "Epoch 140/150, Loss: 0.5279908180236816\n",
      "Epoch 141/150, Loss: 1.3070447444915771\n",
      "Epoch 142/150, Loss: 0.9024471044540405\n",
      "Epoch 143/150, Loss: 1.064028263092041\n",
      "Epoch 144/150, Loss: 1.149377703666687\n",
      "Epoch 145/150, Loss: 0.5321940779685974\n",
      "Epoch 146/150, Loss: 0.5543301701545715\n",
      "Epoch 147/150, Loss: 0.3559964895248413\n",
      "Epoch 148/150, Loss: 1.2557780742645264\n",
      "Epoch 149/150, Loss: 0.4246533513069153\n",
      "Epoch 150/150, Loss: 0.551659345626831\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 150\n",
    "train(model, dataloader_train, criterion, optimizer, num_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53c2576e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.39999999999999"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, dataloader_test, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
